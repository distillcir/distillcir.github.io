<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Zero-Shot Composed Image Retrieval via Dual-Stream Instruction-Aware Distillation</title>
  <link rel="icon" type="image/x-icon" href="static/images/distillcir.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Zero-Shot Composed Image Retrieval via Dual-Stream Instruction-Aware Distillation</h1>
            <h2 class="subtitle is-3 has-text-centered">ICCV 2025</h2>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Wenliang Zhong<sup>1</sup>,
              </span>
              <span class="author-block">
                Rob Barton<sup>2</sup>,
              </span>
              <span class="author-block">
                Weizhi An<sup>1</sup>,
              </span>
              <span class="author-block">
                Feng Jiang<sup>1</sup>,
              </span>
              <span class="author-block">
                Hehuan Ma<sup>1</sup>,
              </span>
              <span class="author-block">
                Yuzhi Guo<sup>1</sup>,
              </span>
              <br>
              <span class="author-block">
                Abhishek Dan<sup>2</sup>,
              </span>
              <span class="author-block">
                Shioulin Sam<sup>2</sup>,
              </span>
              <span class="author-block">
                Karim Bouyarmane<sup>2</sup>,
              </span>
              <span class="author-block">
                Junzhou Huang<sup>1</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup> UT Arlington</span><br>
              <span class="author-block"><sup>2</sup> Amazon</span>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                        <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://distillcir.github.io/" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://distillcir.github.io/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming Soon)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://distillcir.github.io/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Overview figure -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <figure class="image">
          <img src="static/images/overview.png" alt="Overview of DistillCIR">
        </figure>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Composed Image Retrieval (CIR) targets the retrieval of images conditioned on a reference image and a textual modification, but constructing labeled triplets (reference image, textual modification, target image) is inherently challenging. Existing Zero-Shot CIR (ZS-CIR) approaches often rely on well-aligned vision-language models (VLMs) to combine visual and textual inputs, or use large language models (LLMs) for richer modification understanding. While LLM-based methods excel in capturing textual details, they are computationally costly, slow to infer, and often restricted by proprietary constraints. In this paper, we argue that the superior performance of LLM-based ZS-CIR methods primarily stems from their capacity to follow instructions, an aspect largely missing in more efficient projection-based models built upon VLMs. To bridge this gap, we introduce DistillCIR, a dual-stream distillation framework that transfers LLMs’ instruction-following capability into compact, projection-based architectures. By synthesizing triplet data with an LLM and incorporating a novel reasoning process, DistillCIR learns both composed retrieval and instruction awareness. In addition, we train an open-source multimodal LLM on the generated data, and further distill its instruction-aware embeddings into the projection-based model. Without any reliance on LLMs at inference, DistillCIR significantly surpasses state-of-the-art ZS-CIR methods in both performance and efficiency, offering a promising direction for instruction-aware, lightweight CIR.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Method figure -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method Overview</h2>
        <div class="content has-text-justified">
          <p>
            <strong>DistillCIR</strong> is a dual-stream distillation framework that transfers instruction-following capabilities from LLMs into lightweight, projection-based CIR models through three complementary training objectives:
          </p>

          <ol>
            <li>
              <strong>Triplet Supervision:</strong> We begin by converting standard image-caption datasets into a triplet format consisting of a reference image, a textual modification, and a modified caption. This synthetic data is used to train the projection-based model with a composed retrieval objective.
            </li>
            <li>
              <strong>Reasoning Distillation:</strong> To capture deeper instruction understanding, we introduce a reasoning distillation objective. The model learns from the LLM’s step-by-step explanation of how the modification changes the original semantics.
            </li>
            <li>
              <strong>Feature Distillation:</strong> We also train an open-source MLLM on the triplet data and use it as a teacher to transfer instruction-aware embeddings into the projection-based model through feature-level distillation.
            </li>
          </ol>

          <p>
            Together, these objectives enable <strong>DistillCIR</strong> to achieve strong instruction comprehension and state-of-the-art retrieval performance, without requiring any LLMs during inference.
          </p>
        </div>
        <figure class="image">
          <img src="static/images/method.png" alt="Method of DistillCIR">
        </figure>
      </div>
    </div>
  </div>
</section>

<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!-- Experiment figure -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experiments</h2>
        <figure class="image">
          <img src="static/images/results.png" alt="Experiments">
        </figure>
        <p class="has-text-centered is-size-6">Experiments of DistillCIR on CIRR and CIRCO</p>
        <figure class="image">
          <img src="static/images/visualization.png" alt="Visualization">
        </figure>
        <p class="has-text-centered is-size-6">Visualization of DistillCIR on CIRCO and FashionIQ</p>
      </div>
    </div>
  </div>
</section>

<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>Coming Soon</code></pre>
  </div>
</section>
<!--End BibTex citation -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
